{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ds = xr.open_dataset(DTU21_path)\n",
    "mss_lon = ds['lon'].values\n",
    "mss_lat = ds['lat'].values\n",
    "mss_data = ds['mss'].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "linear_interpolator = RegularGridInterpolator((mss_lat, mss_lon), mss_data, method='linear', bounds_error=False, fill_value=np.nan)\n",
    "nearest_interpolator = RegularGridInterpolator((mss_lat, mss_lon), mss_data, method='nearest', bounds_error=False, fill_value=np.nan)\n",
    "\n",
    "# 用 MSS 在points上进行线性插值，结果为nan的值再用最邻近方法填补\n",
    "\n",
    "def combined_interpolation(icesat2_df):\n",
    "    \n",
    "    points = np.array(list(zip(icesat2_df['Latitude'], icesat2_df['Longitude'])))\n",
    "    mss_values_linear = linear_interpolator(points)\n",
    "    mask_nan = np.isnan(mss_values_linear)\n",
    "    mss_values_nearest = nearest_interpolator(points[mask_nan])\n",
    "    mss_values_linear[mask_nan] = mss_values_nearest\n",
    "\n",
    "    return mss_values_linear\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "folder_path = ATL12_path\n",
    "def read_ICESat2_h5(folder_path):\n",
    "\n",
    "    beam_map = {\n",
    "        'beam1': {'forward': 'gt3r', 'backward': 'gt1l'},\n",
    "        'beam3': {'forward': 'gt2r', 'backward': 'gt2l'},\n",
    "        'beam5': {'forward': 'gt1r', 'backward': 'gt3l'}\n",
    "    }\n",
    "\n",
    "    file_paths = [os.path.join(folder_path, f) for f in os.listdir(folder_path) if f.endswith('.h5')]\n",
    "    \n",
    "    for file_path in file_paths:\n",
    "        try:\n",
    "            file_name = os.path.basename(file_path).split('_')[1]\n",
    "            date_str = file_name[:14]\n",
    "            date_obj = datetime.strptime(date_str, '%Y%m%d%H%M%S')\n",
    "\n",
    "            with h5py.File(file_path, 'r') as h5_file:\n",
    "                sc_orient = h5_file['orbit_info/sc_orient'][:]\n",
    "                if 2 in sc_orient: #transition\n",
    "                    continue\n",
    "\n",
    "                cycle_number = h5_file['orbit_info/cycle_number'][0]\n",
    "                sc_orient_mode = sc_orient[0]\n",
    "                rgt_numbers = h5_file['orbit_info/rgt'][:]\n",
    "                rgt_str = '-'.join(map(str, rgt_numbers))\n",
    "                for beam, mapping in beam_map.items():\n",
    "                    beam_name = mapping['forward'] if sc_orient_mode == 1 else mapping['backward']\n",
    "                    \n",
    "                    lon = h5_file[f'{beam_name}/ssh_segments/longitude'][:]\n",
    "                    lat = h5_file[f'{beam_name}/ssh_segments/latitude'][:]\n",
    "                    h = h5_file[f'{beam_name}/ssh_segments/heights/h'][:]\n",
    "                    tide_ocean_seg = h5_file[f'{beam_name}/ssh_segments/stats/tide_ocean_seg'][:]\n",
    "                    tide_load_seg = h5_file[f'{beam_name}/ssh_segments/stats/tide_load_seg'][:]\n",
    "                    dac_seg = h5_file[f'{beam_name}/ssh_segments/stats/dac_seg'][:]\n",
    "\n",
    "                    data = {\n",
    "                        'Longitude': lon,\n",
    "                        'Latitude': lat,\n",
    "                        'SSH': h,\n",
    "                        'Tide_Ocean': tide_ocean_seg,\n",
    "                        'Tide_Load': tide_load_seg,\n",
    "                        'DAC': dac_seg,\n",
    "                        'Date': [date_obj] * len(lon)\n",
    "                    }\n",
    "                    df = pd.DataFrame(data)\n",
    "\n",
    "             \n",
    "                    df = df[(df['Longitude'] >= 100) & (df['Longitude'] <= 140) &\n",
    "                            (df['Latitude'] >= 0) & (df['Latitude'] <= 50)]\n",
    "                    \n",
    "                    if not df.empty:\n",
    "                        # 计算SSHA & TWLE\n",
    "                        mss_values = combined_interpolation(df)\n",
    "                        df['MSS'] = combined_interpolation(df)\n",
    "                        df['SSHA_DTU21'] = df['SSH'] - mss_values\n",
    "                        df['TWLE'] = df['SSH'] - df['MSS']+ df['Tide_Ocean'] + df['DAC'] + df['Tide_Load']\n",
    "                   \n",
    "                        cycle_folder = os.path.join(folder_path, f\"cycle_{cycle_number}\", beam)\n",
    "                        os.makedirs(cycle_folder, exist_ok=True)\n",
    "                        \n",
    "        \n",
    "                        output_file = os.path.join(cycle_folder, f\"{beam}_cycle_{cycle_number}_{date_str}_{rgt_str}.csv\")\n",
    "                        df.to_csv(output_file, index=False)\n",
    "        except Exception as e:\n",
    "            print(f\"Error reading file {file_path}: {e}\")\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
